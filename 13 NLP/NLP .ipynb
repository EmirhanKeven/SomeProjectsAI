{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b8be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emirh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Eğer stopwords corpusu henüz indirilmediyse indirin\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e348052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NLPlabeledData.tsv\",delimiter=\"\\t\",quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fd0218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f876af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23110f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1900d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simdi veri temizleme islemine gecelim yp nin anlamasi icin, metindeki harflerin hepsi kucuk harf yapilacak\n",
    "# noktalama isaretleri temizlenecek ve sayilar ile anlamsiz kelimeler cikarilacak\n",
    "# (anlamsiz kelimelerden kasit inglizcedeki is are gibi tek basina anlami olmayan kelimeler \"stop word\" diye gecer ayrica)\n",
    "\n",
    "def process(review):\n",
    "    # review without html tags\n",
    "    review = BeautifulSoup(review).get_text()\n",
    "    # review without punctuation \n",
    "    review = re.sub(\"[^a-zA-Z]\", ' ', review)\n",
    "    # converting into lowercase and splitting to eliminate stop words\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    # review without stop words\n",
    "    swords = set(stopwords.words(\"english\"))\n",
    "    review = [w for w in review if w not in swords]\n",
    "    return (\" \".join(review))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e33766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emirh\\AppData\\Local\\Temp\\ipykernel_22192\\310373298.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review = BeautifulSoup(review).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of reviews processed  1000\n",
      "No of reviews processed  2000\n",
      "No of reviews processed  3000\n",
      "No of reviews processed  4000\n",
      "No of reviews processed  5000\n",
      "No of reviews processed  6000\n",
      "No of reviews processed  7000\n",
      "No of reviews processed  8000\n",
      "No of reviews processed  9000\n",
      "No of reviews processed  10000\n",
      "No of reviews processed  11000\n",
      "No of reviews processed  12000\n",
      "No of reviews processed  13000\n",
      "No of reviews processed  14000\n",
      "No of reviews processed  15000\n",
      "No of reviews processed  16000\n",
      "No of reviews processed  17000\n",
      "No of reviews processed  18000\n",
      "No of reviews processed  19000\n",
      "No of reviews processed  20000\n",
      "No of reviews processed  21000\n",
      "No of reviews processed  22000\n",
      "No of reviews processed  23000\n",
      "No of reviews processed  24000\n",
      "No of reviews processed  25000\n"
     ]
    }
   ],
   "source": [
    "# bi usteki fonksiyon ile datayi temizliyoruz\n",
    "# her 1000 review temizleme sonrasi ekrana yazdiyoruz ki ilermeyi gorebilelim\n",
    "\n",
    "train_x_tum = []\n",
    "for r in range(len(df[\"review\"])):\n",
    "    if (r+1)%1000 == 0:\n",
    "        print(\"No of reviews processed \", r+1)\n",
    "    train_x_tum.append(process(df[\"review\"][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d91e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verileri bolelim egitim icin\n",
    "x = train_x_tum\n",
    "y = np.array(df[\"sentiment\"])\n",
    "\n",
    "train_x,test_x , y_train , y_text = train_test_split(x,y,  test_size = 0.1 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34fd18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn deki countvectorizer fonksiyonu ile 5000 kelimelik bag of words olusturuyoruz\n",
    "vectorizer = CountVectorizer(max_features = 5000)\n",
    "# train verilemizi feature vektore matrisine ceviriyoruz\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "# array a donuturuyoruz \n",
    "train_x = train_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87205e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modeli olusturalim\n",
    "train_y = y_train\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9d71c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simdi test datasini matrise cevirelim\n",
    "test_xx = vectorizer.transform(test_x)\n",
    "text_xx = test_xx.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5956b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogruluk orani  84.16495093520169\n"
     ]
    }
   ],
   "source": [
    "# dogrulugumuza bakalim\n",
    "test_prediction = model.predict(test_xx)\n",
    "dogruluk = roc_auc_score(y_text, test_prediction)\n",
    "print(\"Dogruluk orani \", dogruluk * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3940794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
